{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-22T07:39:50.366883Z",
     "start_time": "2023-07-22T07:39:50.346708500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import nibabel as nib\n",
    "from nibabel.viewers import OrthoSlicer3D\n",
    "\n",
    "train_path = glob.glob('./脑PET图像分析和疾病预测挑战赛数据集/Train/*/*')\n",
    "test_path = glob.glob('./脑PET图像分析和疾病预测挑战赛数据集/Test/*')\n",
    "\n",
    "np.random.shuffle(train_path)\n",
    "np.random.shuffle(test_path)\n",
    "\n",
    "DATA_CACHE = {}\n",
    "\n",
    "\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.img_path[index] in DATA_CACHE:\n",
    "            img = DATA_CACHE[self.img_path[index]]\n",
    "        else:\n",
    "            img = nib.load(self.img_path[index])\n",
    "            img = img.dataobj[:, :, :, 0]\n",
    "            DATA_CACHE[self.img_path[index]] = img\n",
    "\n",
    "        # 随机选择一些通道\n",
    "        idx = np.random.choice(range(img.shape[-1]), 64)\n",
    "        img = img[:, :, idx]\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        img = img.transpose([2, 0, 1])\n",
    "        return img, torch.from_numpy(np.array(int('NC' in self.img_path[index])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[:-10],\n",
    "                  A.Compose([\n",
    "                      A.RandomRotate90(),\n",
    "                      A.RandomCrop(120, 120),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.RandomBrightnessContrast(p=0.5),\n",
    "                  ])\n",
    "                  ), batch_size=2, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[-10:],\n",
    "                  A.Compose([\n",
    "                      A.RandomCrop(120, 120),\n",
    "                  ])\n",
    "                  ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(test_path,\n",
    "                  A.Compose([\n",
    "                      A.RandomCrop(128, 128),\n",
    "                      A.HorizontalFlip(p=0.5),\n",
    "                      A.RandomBrightnessContrast(p=0.5),\n",
    "                  ])\n",
    "                  ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\code\\pycharm\\pytorch\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "E:\\code\\pycharm\\pytorch\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet, self).__init__()\n",
    "\n",
    "        model = models.resnet18(True)\n",
    "        model.conv1 = torch.nn.Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(512, 2)\n",
    "        self.resnet = model\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = XunFeiNet()\n",
    "model = model.to('cuda')\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T07:39:52.630512500Z",
     "start_time": "2023-07-22T07:39:52.220176800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 41\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m val_acc \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(val_loader\u001B[38;5;241m.\u001B[39mdataset)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m---> 41\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m     val_acc \u001B[38;5;241m=\u001B[39m validate(val_loader, model, criterion)\n\u001B[0;32m     43\u001B[0m     train_acc \u001B[38;5;241m=\u001B[39m validate(train_loader, model, criterion)\n",
      "Cell \u001B[1;32mIn[4], line 11\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(train_loader, model, criterion, optimizer)\u001B[0m\n\u001B[0;32m      8\u001B[0m output \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#print(output.dtype)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m#print(target.long().dtype)\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mE:\\code\\pycharm\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mE:\\code\\pycharm\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1176\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\code\\pycharm\\pytorch\\venv\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3028\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3029\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Int'"
     ]
    }
   ],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        #print(output.dtype)\n",
    "        #print(target.long().dtype)\n",
    "        loss = criterion(output, target.long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target.long())\n",
    "\n",
    "            val_acc += (output.argmax(1) == target).sum().item()\n",
    "\n",
    "    return val_acc / len(val_loader.dataset)\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc = validate(val_loader, model, criterion)\n",
    "    train_acc = validate(train_loader, model, criterion)\n",
    "\n",
    "    print(train_loss, train_acc, val_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T07:40:04.438427300Z",
     "start_time": "2023-07-22T07:40:02.361565600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def predict(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "\n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            output = model(input)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "\n",
    "    return np.vstack(test_pred)\n",
    "\n",
    "\n",
    "pred = None\n",
    "for _ in range(10):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model, criterion)\n",
    "    else:\n",
    "        pred += predict(test_loader, model, criterion)\n",
    "\n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'uuid': [int(x.split('\\\\')[-1][:-4]) for x in test_path],\n",
    "        'label': pred.argmax(1)\n",
    "    })\n",
    "submit['label'] = submit['label'].map({1: 'NC', 0: 'MCI'})\n",
    "submit = submit.sort_values(by='uuid')\n",
    "submit.to_csv('submit.csv', index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T16:02:59.658273100Z",
     "start_time": "2023-07-21T16:02:44.848998500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
